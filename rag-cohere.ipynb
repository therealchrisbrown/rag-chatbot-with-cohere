{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RAG chatbot using cohere \n",
    "\n",
    "## First: Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build documents component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import cohere\n",
    "import os\n",
    "import hnswlib\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Dict, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "co = cohere.Client(os.environ[\"COHERE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocumentCollection Class\n",
    "\n",
    "A class representing a collection of documents.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- **sources** (list): A list of dictionaries representing the sources of the documents. Each dictionary should have 'title' and 'url' keys.\n",
    "\n",
    "## Attributes\n",
    "\n",
    "- **sources** (list): A list of dictionaries representing the sources of the documents.\n",
    "- **docs** (list): A list of dictionaries representing the documents, with 'title', 'content', and 'url' keys.\n",
    "- **docs_embs** (list): A list of the associated embeddings for the documents.\n",
    "- **retrieve_top_k** (int): The number of documents to retrieve during search.\n",
    "- **rerank_top_k** (int): The number of documents to rerank after retrieval.\n",
    "- **docs_len** (int): The number of documents in the collection.\n",
    "- **index** (hnswlib.Index): The index used for document retrieval.\n",
    "\n",
    "## Methods\n",
    "\n",
    "- **load():** Loads the data from the sources and partitions the HTML content into chunks.\n",
    "- **embed():** Embeds the documents using the Cohere API.\n",
    "- **index():** Indexes the documents for efficient retrieval.\n",
    "- **retrieve(query):** Retrieves documents based on the given query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Documents:\n",
    "\n",
    "\n",
    "    def __init__(self, sources: List[Dict[str, str]]):\n",
    "        self.sources = sources\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the documents from the sources and chunks the HTML content.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for source in self.sources:\n",
    "            elements = partition_html(url=source[\"url\"])\n",
    "            chunks = chunk_by_title(elements)\n",
    "            for chunk in chunks:\n",
    "                self.docs.append(\n",
    "                    {\n",
    "                        \"title\": source[\"title\"],\n",
    "                        \"text\": str(chunk),\n",
    "                        \"url\": source[\"url\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the documents using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding documents...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the documents for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing documents...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the given query.\n",
    "\n",
    "        Parameters:\n",
    "        query (str): The query to retrieve documents for.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents, with 'title', 'text', and 'url' keys.\n",
    "        \"\"\"\n",
    "        docs_retrieved = []\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "\n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "\n",
    "        docs_to_rerank = []\n",
    "        for doc_id in doc_ids:\n",
    "            docs_to_rerank.append(self.docs[doc_id][\"text\"])\n",
    "\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v2.0\",\n",
    "        )\n",
    "\n",
    "        doc_ids_reranked = []\n",
    "        for result in rerank_results:\n",
    "            doc_ids_reranked.append(doc_ids[result.index])\n",
    "\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            docs_retrieved.append(\n",
    "                {\n",
    "                    \"title\": self.docs[doc_id][\"title\"],\n",
    "                    \"text\": self.docs[doc_id][\"text\"],\n",
    "                    \"url\": self.docs[doc_id][\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return docs_retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Class\n",
    "\n",
    "A class representing a chatbot.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- **docs** (*Documents*): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "## Attributes\n",
    "\n",
    "- **conversation_id** (*str*): The unique ID for the conversation.\n",
    "- **docs** (*Documents*): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "## Methods\n",
    "\n",
    "- **generate_response(message):** Generates a response to the user's message.\n",
    "- **retrieve_docs(response):** Retrieves documents based on the search queries in the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "\n",
    "\n",
    "    def __init__(self, docs: Documents):\n",
    "        self.docs = docs\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "\n",
    "    def generate_response(self, message: str):\n",
    "        \"\"\"\n",
    "        Generates a response to the user's message.\n",
    "\n",
    "        Parameters:\n",
    "        message (str): The user's message.\n",
    "\n",
    "        Yields:\n",
    "        Event: A response event generated by the chatbot.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Generate search queries (if any)\n",
    "        response = co.chat(message=message, search_queries_only=True)\n",
    "\n",
    "        # If there are search queries, retrieve documents and respond\n",
    "        if response.search_queries:\n",
    "            print(\"Retrieving information...\")\n",
    "\n",
    "            documents = self.retrieve_docs(response)\n",
    "\n",
    "            response = co.chat(\n",
    "                message=message,\n",
    "                documents=documents,\n",
    "                conversation_id=self.conversation_id,\n",
    "                stream=True,\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "\n",
    "        # If there is no search query, directly respond\n",
    "        else:\n",
    "            response = co.chat(\n",
    "                message=message, \n",
    "                conversation_id=self.conversation_id, \n",
    "                stream=True\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "\n",
    "    def retrieve_docs(self, response) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the search queries in the response.\n",
    "\n",
    "        Parameters:\n",
    "        response: The response object containing search queries.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get the query(s)\n",
    "        queries = []\n",
    "        for search_query in response.search_queries:\n",
    "            queries.append(search_query[\"text\"])\n",
    "\n",
    "        # Retrieve documents for each query\n",
    "        retrieved_docs = []\n",
    "        for query in queries:\n",
    "            retrieved_docs.extend(self.docs.retrieve(query))\n",
    "\n",
    "        # # Uncomment this code block to display the chatbot's retrieved documents\n",
    "        # print(\"DOCUMENTS RETRIEVED:\")\n",
    "        # for idx, doc in enumerate(retrieved_docs):\n",
    "        #     print(f\"doc_{idx}: {doc}\")\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        return retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App Initialization\n",
    "\n",
    "Initializes an instance of the App class.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- **chatbot** (*Chatbot*): An instance of the Chatbot class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "class App:\n",
    "    def __init__(self, chatbot: Chatbot):\n",
    "\n",
    "        self.chatbot = chatbot\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the chatbot application.\n",
    "\n",
    "        \"\"\"\n",
    "        st.title(\"RAG-Chatbot Application\")\n",
    "\n",
    "        user_input = st.text_input(\"User\", \"\")\n",
    "\n",
    "        if st.button(\"Submit\"):\n",
    "            #Typing \"quit\" ends the conversation\n",
    "            if user_input.lower() == \"quit\":\n",
    "                st.write(\"Ending chat.\")\n",
    "            else:\n",
    "                st.text(f\"User: {user_input}\")\n",
    "                        \n",
    "                #Get response\n",
    "                response = self.chatbot.generate_response(user_input)\n",
    "                        \n",
    "                st.write(\"Chatbot: \")\n",
    "                for event in response:\n",
    "                    # Text\n",
    "                    if event.event_type == \"text-generation\":\n",
    "                        st.write(event.text, end=\"\")\n",
    "\n",
    "                    # Citations\n",
    "                    if event.event_type == \"citation-generation\":\n",
    "                        st.write(\"\\n\\nCITATIONS:\")\n",
    "                        st.write(event.citations)\n",
    "                st.write(f\"\\n{'-'*100}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User\n",
    "I wrote an App class in Python to create a simple chatbot. I want to use some more advanced user interface - like streamlit. Can you help to create one?\n",
    "\n",
    "App class = \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sources for the documents - here cohere website\n",
    "\n",
    "sources = [\n",
    "    {\n",
    "        \"title\": \"Text Embeddings\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
    "    {\n",
    "        \"title\": \"Similarity Between Words and Sentences\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
    "    {\n",
    "        \"title\": \"The Attention Mechanism\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
    "    {\n",
    "        \"title\": \"Transformer Models\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/transformer-models\"}   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Embedding documents...\n",
      "Indexing documents...\n",
      "Indexing complete with 136 documents.\n"
     ]
    }
   ],
   "source": [
    "# Now create an instance of the documents class -> process the documents \n",
    "\n",
    "documents = Documents(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance of the chatbot class\n",
    "chatbot = Chatbot(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance if the app class\n",
    "app = App(chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 16:13:18.356 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/christianbraun/opt/miniconda3/envs/cohere-test/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohere-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
