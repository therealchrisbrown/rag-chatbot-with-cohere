{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RAG chatbot using cohere \n",
    "\n",
    "## First: Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build documents component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import cohere\n",
    "import os\n",
    "import hnswlib\n",
    "import json\n",
    "import uuid\n",
    "from typing import List, Dict, Dict\n",
    "from unstructured.partition.html import partition_html\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "\n",
    "co = cohere.Client(os.environ[\"COHERE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocumentCollection Class\n",
    "\n",
    "A class representing a collection of documents.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- **sources** (list): A list of dictionaries representing the sources of the documents. Each dictionary should have 'title' and 'url' keys.\n",
    "\n",
    "## Attributes\n",
    "\n",
    "- **sources** (list): A list of dictionaries representing the sources of the documents.\n",
    "- **docs** (list): A list of dictionaries representing the documents, with 'title', 'content', and 'url' keys.\n",
    "- **docs_embs** (list): A list of the associated embeddings for the documents.\n",
    "- **retrieve_top_k** (int): The number of documents to retrieve during search.\n",
    "- **rerank_top_k** (int): The number of documents to rerank after retrieval.\n",
    "- **docs_len** (int): The number of documents in the collection.\n",
    "- **index** (hnswlib.Index): The index used for document retrieval.\n",
    "\n",
    "## Methods\n",
    "\n",
    "- **load():** Loads the data from the sources and partitions the HTML content into chunks.\n",
    "- **embed():** Embeds the documents using the Cohere API.\n",
    "- **index():** Indexes the documents for efficient retrieval.\n",
    "- **retrieve(query):** Retrieves documents based on the given query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Documents:\n",
    "\n",
    "\n",
    "    def __init__(self, sources: List[Dict[str, str]]):\n",
    "        self.sources = sources\n",
    "        self.docs = []\n",
    "        self.docs_embs = []\n",
    "        self.retrieve_top_k = 10\n",
    "        self.rerank_top_k = 3\n",
    "        self.load()\n",
    "        self.embed()\n",
    "        self.index()\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"\n",
    "        Loads the documents from the sources and chunks the HTML content.\n",
    "        \"\"\"\n",
    "        print(\"Loading documents...\")\n",
    "\n",
    "        for source in self.sources:\n",
    "            elements = partition_html(url=source[\"url\"])\n",
    "            chunks = chunk_by_title(elements)\n",
    "            for chunk in chunks:\n",
    "                self.docs.append(\n",
    "                    {\n",
    "                        \"title\": source[\"title\"],\n",
    "                        \"text\": str(chunk),\n",
    "                        \"url\": source[\"url\"],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def embed(self) -> None:\n",
    "        \"\"\"\n",
    "        Embeds the documents using the Cohere API.\n",
    "        \"\"\"\n",
    "        print(\"Embedding documents...\")\n",
    "\n",
    "        batch_size = 90\n",
    "        self.docs_len = len(self.docs)\n",
    "\n",
    "        for i in range(0, self.docs_len, batch_size):\n",
    "            batch = self.docs[i : min(i + batch_size, self.docs_len)]\n",
    "            texts = [item[\"text\"] for item in batch]\n",
    "            docs_embs_batch = co.embed(\n",
    "                texts=texts, model=\"embed-english-v3.0\", input_type=\"search_document\"\n",
    "            ).embeddings\n",
    "            self.docs_embs.extend(docs_embs_batch)\n",
    "\n",
    "    def index(self) -> None:\n",
    "        \"\"\"\n",
    "        Indexes the documents for efficient retrieval.\n",
    "        \"\"\"\n",
    "        print(\"Indexing documents...\")\n",
    "\n",
    "        self.idx = hnswlib.Index(space=\"ip\", dim=1024)\n",
    "        self.idx.init_index(max_elements=self.docs_len, ef_construction=512, M=64)\n",
    "        self.idx.add_items(self.docs_embs, list(range(len(self.docs_embs))))\n",
    "\n",
    "        print(f\"Indexing complete with {self.idx.get_current_count()} documents.\")\n",
    "\n",
    "    def retrieve(self, query: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the given query.\n",
    "\n",
    "        Parameters:\n",
    "        query (str): The query to retrieve documents for.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents, with 'title', 'text', and 'url' keys.\n",
    "        \"\"\"\n",
    "        docs_retrieved = []\n",
    "        query_emb = co.embed(\n",
    "            texts=[query], model=\"embed-english-v3.0\", input_type=\"search_query\"\n",
    "        ).embeddings\n",
    "\n",
    "        doc_ids = self.idx.knn_query(query_emb, k=self.retrieve_top_k)[0][0]\n",
    "\n",
    "        docs_to_rerank = []\n",
    "        for doc_id in doc_ids:\n",
    "            docs_to_rerank.append(self.docs[doc_id][\"text\"])\n",
    "\n",
    "        rerank_results = co.rerank(\n",
    "            query=query,\n",
    "            documents=docs_to_rerank,\n",
    "            top_n=self.rerank_top_k,\n",
    "            model=\"rerank-english-v2.0\",\n",
    "        )\n",
    "\n",
    "        doc_ids_reranked = []\n",
    "        for result in rerank_results:\n",
    "            doc_ids_reranked.append(doc_ids[result.index])\n",
    "\n",
    "        for doc_id in doc_ids_reranked:\n",
    "            docs_retrieved.append(\n",
    "                {\n",
    "                    \"title\": self.docs[doc_id][\"title\"],\n",
    "                    \"text\": self.docs[doc_id][\"text\"],\n",
    "                    \"url\": self.docs[doc_id][\"url\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        return docs_retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Class\n",
    "\n",
    "A class representing a chatbot.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- **docs** (*Documents*): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "## Attributes\n",
    "\n",
    "- **conversation_id** (*str*): The unique ID for the conversation.\n",
    "- **docs** (*Documents*): An instance of the Documents class representing the collection of documents.\n",
    "\n",
    "## Methods\n",
    "\n",
    "- **generate_response(message):** Generates a response to the user's message.\n",
    "- **retrieve_docs(response):** Retrieves documents based on the search queries in the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "\n",
    "\n",
    "    def __init__(self, docs: Documents):\n",
    "        self.docs = docs\n",
    "        self.conversation_id = str(uuid.uuid4())\n",
    "\n",
    "    def generate_response(self, message: str):\n",
    "        \"\"\"\n",
    "        Generates a response to the user's message.\n",
    "\n",
    "        Parameters:\n",
    "        message (str): The user's message.\n",
    "\n",
    "        Yields:\n",
    "        Event: A response event generated by the chatbot.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Generate search queries (if any)\n",
    "        response = co.chat(message=message, search_queries_only=True)\n",
    "\n",
    "        # If there are search queries, retrieve documents and respond\n",
    "        if response.search_queries:\n",
    "            print(\"Retrieving information...\")\n",
    "\n",
    "            documents = self.retrieve_docs(response)\n",
    "\n",
    "            response = co.chat(\n",
    "                message=message,\n",
    "                documents=documents,\n",
    "                conversation_id=self.conversation_id,\n",
    "                stream=True,\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "\n",
    "        # If there is no search query, directly respond\n",
    "        else:\n",
    "            response = co.chat(\n",
    "                message=message, \n",
    "                conversation_id=self.conversation_id, \n",
    "                stream=True\n",
    "            )\n",
    "            for event in response:\n",
    "                yield event\n",
    "\n",
    "    def retrieve_docs(self, response) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Retrieves documents based on the search queries in the response.\n",
    "\n",
    "        Parameters:\n",
    "        response: The response object containing search queries.\n",
    "\n",
    "        Returns:\n",
    "        List[Dict[str, str]]: A list of dictionaries representing the retrieved documents.\n",
    "\n",
    "        \"\"\"\n",
    "        # Get the query(s)\n",
    "        queries = []\n",
    "        for search_query in response.search_queries:\n",
    "            queries.append(search_query[\"text\"])\n",
    "\n",
    "        # Retrieve documents for each query\n",
    "        retrieved_docs = []\n",
    "        for query in queries:\n",
    "            retrieved_docs.extend(self.docs.retrieve(query))\n",
    "\n",
    "        # # Uncomment this code block to display the chatbot's retrieved documents\n",
    "        # print(\"DOCUMENTS RETRIEVED:\")\n",
    "        # for idx, doc in enumerate(retrieved_docs):\n",
    "        #     print(f\"doc_{idx}: {doc}\")\n",
    "        # print(\"\\n\")\n",
    "\n",
    "        return retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App Initialization\n",
    "\n",
    "Initializes an instance of the App class.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- **chatbot** (*Chatbot*): An instance of the Chatbot class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class App:\n",
    "    def __init__(self, chatbot: Chatbot):\n",
    "        \"\"\"\n",
    "        Initializes an instance of the App class.\n",
    "\n",
    "        Parameters:\n",
    "        chatbot (Chatbot): An instance of the Chatbot class.\n",
    "\n",
    "        \"\"\"\n",
    "        self.chatbot = chatbot\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the chatbot application.\n",
    "\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Get the user message\n",
    "            message = input(\"User: \")\n",
    "\n",
    "            # Typing \"quit\" ends the conversation\n",
    "            if message.lower() == \"quit\":\n",
    "                print(\"Ending chat.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"User: {message}\")\n",
    "\n",
    "            # Get the chatbot response\n",
    "            response = self.chatbot.generate_response(message)\n",
    "\n",
    "            # Print the chatbot response\n",
    "            print(\"Chatbot:\")\n",
    "            flag = False\n",
    "            for event in response:\n",
    "                # Text\n",
    "                if event.event_type == \"text-generation\":\n",
    "                    print(event.text, end=\"\")\n",
    "\n",
    "                # Citations\n",
    "                if event.event_type == \"citation-generation\":\n",
    "                    if not flag:\n",
    "                        print(\"\\n\\nCITATIONS:\")\n",
    "                        flag = True\n",
    "                    print(event.citations)\n",
    "\n",
    "            print(f\"\\n{'-'*100}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User\n",
    "I wrote an App class in Python to create a simple chatbot. I want to use some more advanced user interface - like streamlit. Can you help to create one?\n",
    "\n",
    "App class = \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sources for the documents - here cohere website\n",
    "\n",
    "sources = [\n",
    "    {\n",
    "        \"title\": \"Text Embeddings\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/text-embeddings\"},\n",
    "    {\n",
    "        \"title\": \"Similarity Between Words and Sentences\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/similarity-between-words-and-sentences\"},\n",
    "    {\n",
    "        \"title\": \"The Attention Mechanism\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/the-attention-mechanism\"},\n",
    "    {\n",
    "        \"title\": \"Transformer Models\", \n",
    "        \"url\": \"https://docs.cohere.com/docs/transformer-models\"}   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents...\n",
      "Embedding documents...\n",
      "Indexing documents...\n",
      "Indexing complete with 136 documents.\n"
     ]
    }
   ],
   "source": [
    "# Now create an instance of the documents class -> process the documents \n",
    "\n",
    "documents = Documents(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance of the chatbot class\n",
    "chatbot = Chatbot(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance if the app class\n",
    "app = App(chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: explain text embeddings in simple terms\n",
      "Chatbot:\n",
      "Retrieving information...\n",
      "Text embeddings are a useful tool for language models. Every word is assigned a list of numbers (vector) in text embeddings in a way that captures its semantic properties. If two words have similar meanings, their vectors will be similar. This contrasts with words that have different meanings, whose vectors will be different. For example, the word \"king\" and \"queen\" would have similar vectors because they are semantically similar. \n",
      "\n",
      "Once the input has been transformed into tokens, these tokens are then turned into numbers. Text embeddings accomplish this by using an embedding. These embedded numbers represent the text in a vector format.\n",
      "\n",
      "CITATIONS:\n",
      "[{'start': 22, 'end': 54, 'text': 'useful tool for language models.', 'document_ids': ['doc_1']}]\n",
      "[{'start': 69, 'end': 123, 'text': 'assigned a list of numbers (vector) in text embeddings', 'document_ids': ['doc_1']}]\n",
      "[{'start': 151, 'end': 171, 'text': 'semantic properties.', 'document_ids': ['doc_1']}]\n",
      "[{'start': 230, 'end': 238, 'text': 'similar.', 'document_ids': ['doc_1']}]\n",
      "[{'start': 317, 'end': 327, 'text': 'different.', 'document_ids': ['doc_1']}]\n",
      "[{'start': 573, 'end': 583, 'text': 'embedding.', 'document_ids': ['doc_2']}]\n",
      "[{'start': 631, 'end': 637, 'text': 'vector', 'document_ids': ['doc_2']}]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "User: is it possible to work multilingual in cohere?\n",
      "Chatbot:\n",
      "Retrieving information...\n",
      "Yes, at Cohere, it is possible to work with multiple languages. Cohere has trained a large multilingual model to unify various languages into one and improve comprehension across different languages. The model can currently process embeddings for sentences in more than 100 languages. \n",
      "\n",
      "Is there a specific language you want to generate embeddings for? I could then check if it's one of the supported languages.\n",
      "\n",
      "CITATIONS:\n",
      "[{'start': 75, 'end': 109, 'text': 'trained a large multilingual model', 'document_ids': ['doc_1']}]\n",
      "[{'start': 113, 'end': 145, 'text': 'unify various languages into one', 'document_ids': ['doc_1']}]\n",
      "[{'start': 260, 'end': 284, 'text': 'more than 100 languages.', 'document_ids': ['doc_2']}]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Ending chat.\n"
     ]
    }
   ],
   "source": [
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do\n",
    "\n",
    "- Build small frontend for output with streamlit\n",
    "- Deploy on Heroku oder Firestore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohere-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
